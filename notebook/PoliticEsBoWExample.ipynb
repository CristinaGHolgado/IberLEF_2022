{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoliticEsBoWExample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PoliticEs 2022 BoW baselines and tutorial\n",
        "This Google Colab is an example of a baseline based on BoW models for the shared-task PoliticEs. Here we show how to load the development dataset and how to train 4 baselines models based on logistic regression with a simple Bag-of-Words (BoW) model for each trait (gender, profession, ideology_binary and ideology_multiclass). In addition, we show how to calculate the final F1-score of each model and how to generate the final submission file.\n",
        "\n",
        "More information regarding the shared task can be found at: https://codalab.lisn.upsaclay.fr/competitions/1948\n"
      ],
      "metadata": {
        "id": "Abt8kpUR6NbJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVmIZ6Zt6Jqc"
      },
      "outputs": [],
      "source": [
        "# The first step is to import the required libraries\n",
        "# We rely on Pandas, Numpy and Scikit-learn in order to manage the input data, \n",
        "# and train the machine-learning models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we load the datasets. \n",
        "# We have the datasets organised into two files. On the one hand, a file for \n",
        "# training and, on the other, one dataset to test the performance of our model\n",
        "!rm development.csv\n",
        "!rm development_test.csv\n",
        "!wget https://pln.inf.um.es/corpora/politices/development.csv --no-check-certificate\n",
        "!wget https://pln.inf.um.es/corpora/politices/development_test.csv --no-check-certificate\n"
      ],
      "metadata": {
        "id": "IhPTCduv6ceI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a216c1f7-0a31-4be9-99aa-f4633ffc4eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-11 17:30:30--  https://pln.inf.um.es/corpora/politices/development.csv\n",
            "Resolving pln.inf.um.es (pln.inf.um.es)... 155.54.204.105\n",
            "Connecting to pln.inf.um.es (pln.inf.um.es)|155.54.204.105|:443... connected.\n",
            "WARNING: cannot verify pln.inf.um.es's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1482900 (1.4M) [text/csv]\n",
            "Saving to: ‘development.csv’\n",
            "\n",
            "development.csv     100%[===================>]   1.41M  1.65MB/s    in 0.9s    \n",
            "\n",
            "2022-02-11 17:30:31 (1.65 MB/s) - ‘development.csv’ saved [1482900/1482900]\n",
            "\n",
            "--2022-02-11 17:30:31--  https://pln.inf.um.es/corpora/politices/development_test.csv\n",
            "Resolving pln.inf.um.es (pln.inf.um.es)... 155.54.204.105\n",
            "Connecting to pln.inf.um.es (pln.inf.um.es)|155.54.204.105|:443... connected.\n",
            "WARNING: cannot verify pln.inf.um.es's certificate, issued by ‘CN=GEANT OV RSA CA 4,O=GEANT Vereniging,C=NL’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305529 (298K) [text/csv]\n",
            "Saving to: ‘development_test.csv’\n",
            "\n",
            "development_test.cs 100%[===================>] 298.37K   548KB/s    in 0.5s    \n",
            "\n",
            "2022-02-11 17:30:32 (548 KB/s) - ‘development_test.csv’ saved [305529/305529]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "oh65XqvAAruY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, the development data files are loaded. As we can see, these files are organised at the document level, that is, each row represents a document of a user (label). For each user, we have two demograhpic traits (gender and profession) and two psychographic traits (binary political ideology and multiclass political ideology)."
      ],
      "metadata": {
        "id": "Bj4Mal6pA5Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training and test file\n",
        "df_train = pd.read_csv ('development.csv')\n",
        "df_test = pd.read_csv ('development_test.csv')\n",
        "\n",
        "# The train dataframe is shown\n",
        "print (df_train)\n",
        "\n",
        "# We can observe that we have 50 documents for each user\n",
        "df_train.groupby ('label').size ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHVCd9OiAtva",
        "outputId": "c12062d1-3dda-4421-e4c0-ff833ac7d922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0  ...                                              tweet\n",
            "0          36617  ...  EE UU y China: Los dos grandes pelean, el mund...\n",
            "1          11991  ...  Sensación Previsible a esta hora: Alegría [POL...\n",
            "2          40804  ...  No te salves. no te quedes inmóvil al borde de...\n",
            "3          48101  ...  Al menos 25 militares venezolanos, todos de ba...\n",
            "4          27627  ...  Rivera que , con Sanchez ,da una mayoría absol...\n",
            "...          ...  ...                                                ...\n",
            "4995        6914  ...  Dani Mateo insiste en Catalunya Radio en sus g...\n",
            "4996       39390  ...  Si.... Una condenada por apología del terroris...\n",
            "4997       44724  ...  Cuidémonos de la “colaboración y lealtad” de C...\n",
            "4998       39401  ...  Cuenta [POLITICAL_PARTY] que el Gobierno se ha...\n",
            "4999       29880  ...  Ese lío de la extrema izquierda con la ley:. D...\n",
            "\n",
            "[5000 rows x 7 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "@user10     50\n",
              "@user105    50\n",
              "@user110    50\n",
              "@user117    50\n",
              "@user12     50\n",
              "            ..\n",
              "@user85     50\n",
              "@user86     50\n",
              "@user93     50\n",
              "@user94     50\n",
              "@user96     50\n",
              "Length: 100, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the baseline\n",
        "In the next cells, we will preprare the training dataset for conducting the \n",
        "author profiling tasks. For this, we will first combine all the documents for \n",
        "each author, and then we will train a Logistic Regression model for each trait."
      ],
      "metadata": {
        "id": "Blqi7WjQNRDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An important stage when we are dealing with author profiling tasks is that \n",
        "# the results should be at author level. However, the dataframe is prepared at \n",
        "# the document-level. Therefore, we are going to merge all the texts from the \n",
        "# same user and concatenate them with a custom separator\n",
        "\n",
        "# From now one, dataframes will contain the dataframes\n",
        "dataframes = {\n",
        "  'train': df_train, \n",
        "  'test': df_test\n",
        "}\n",
        "\n",
        "# NOTE: As loops does not bind variable data, we do sequence unpacking\n",
        "for key, df in dataframes.items ():\n",
        "\n",
        "  # These columns are shared for all documents of each user\n",
        "  columns_to_group_by_user = ['label', 'gender', 'profession', 'ideology_binary', 'ideology_multiclass']\n",
        "\n",
        "\n",
        "  # Group the dataframe by user (label)\n",
        "  group = df.groupby (by = columns_to_group_by_user, dropna = False, observed = True, sort = False)\n",
        "\n",
        "\n",
        "  # Create a custom dataframe per user\n",
        "  df_users = group[columns_to_group_by_user].agg (func = ['count'], as_index = False, observed = True).index.to_frame (index = False)\n",
        "\n",
        "\n",
        "  # Temporal variable\n",
        "  merged_fields = []\n",
        "\n",
        "\n",
        "  # We merge the documents with a fancy TQDM progress bar\n",
        "  pbar = tqdm (df_users.iterrows (), total = df_users.shape[0], desc = \"merging users\")\n",
        "    \n",
        "    \n",
        "  # Iterate over rows in a fancy way\n",
        "  for index, row in pbar:\n",
        "      df_user = df[(df['label'] == row['label'])]\n",
        "      merged_fields.append ({**row, **{field: ' [SEP] '.join (df_user[field].fillna ('')) for field in ['tweet']}})\n",
        "    \n",
        "  # Modify the original variable dataframe\n",
        "  dataframes[key] = pd.DataFrame (merged_fields)\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv7k2EQKCpf1",
        "outputId": "e2e968bc-7ea9-4337-f073-17351c7ade43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "merging users: 100%|██████████| 101/101 [00:00<00:00, 674.74it/s]\n",
            "merging users: 100%|██████████| 20/20 [00:00<00:00, 932.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TFIDF Vectorizer using sci-kit. With this, we are going to represent all texts\n",
        "# as counts of the vocabulary. \n",
        "vectorizer = TfidfVectorizer (\n",
        "  analyzer = 'word',\n",
        "  min_df = .1,\n",
        "  max_features = 5000,\n",
        "  lowercase = True\n",
        ") \n",
        "\n",
        "\n",
        "# Get the TF-IDF values from the training set\n",
        "X_train = vectorizer.fit_transform (dataframes['train']['tweet'])\n",
        "\n",
        "# Get the TF-IDF values from the test set\n",
        "# Note that we apply the TF-IDF learned from the training split \n",
        "X_test = vectorizer.transform (dataframes['test']['tweet'])\n",
        "\n",
        "\n",
        "# We are going to store a baseline per trait\n",
        "baselines = {}\n",
        "\n",
        "# As we observed, this task is about four traits: two demographic and two psychographic. Therefore, we are going to\n",
        "# train different and separate models for each task\n",
        "for label in ['gender', 'profession', 'ideology_binary', 'ideology_multiclass']:\n",
        "\n",
        "  # Get a baseline classifier\n",
        "  baselines[label] = LogisticRegression ()\n",
        "\n",
        "\n",
        "  # Train the baseline for this label\n",
        "  baselines[label].fit (X_train, dataframes['train'][label])\n",
        "\n"
      ],
      "metadata": {
        "id": "bYq5aLip6t79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the baseline\n",
        "Next, once we already have the models trained, we are going to calculate the scores of the results. Note that we can do this as we have the official test labels in the development_test.csv file."
      ],
      "metadata": {
        "id": "F6pJnNQhvpnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the result\n",
        "# As we observed, this task is about four traits: two demographic and two psychographic. Therefore, we are going to\n",
        "# train different models for each task\n",
        "# Note that we are doing this because we know the labels on the test set\n",
        "for label in ['gender', 'profession', 'ideology_binary', 'ideology_multiclass']:\n",
        "\n",
        "  # Get the predictions\n",
        "  y_pred = baselines[label].predict (X_test)\n",
        "\n",
        "  # Then the results are printed\n",
        "  print (label)\n",
        "  print (classification_report (dataframes['test'][label], y_pred, zero_division = 0, digits = 6))\n",
        "\n"
      ],
      "metadata": {
        "id": "cZGYCH2L6v7n",
        "outputId": "a375e754-284c-4342-febd-1ec2e5c7be2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gender\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female   0.166667  0.250000  0.200000         4\n",
            "        male   0.785714  0.687500  0.733333        16\n",
            "\n",
            "    accuracy                       0.600000        20\n",
            "   macro avg   0.476190  0.468750  0.466667        20\n",
            "weighted avg   0.661905  0.600000  0.626667        20\n",
            "\n",
            "profession\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  journalist   0.000000  0.000000  0.000000         6\n",
            "  politician   0.700000  1.000000  0.823529        14\n",
            "\n",
            "    accuracy                       0.700000        20\n",
            "   macro avg   0.350000  0.500000  0.411765        20\n",
            "weighted avg   0.490000  0.700000  0.576471        20\n",
            "\n",
            "ideology_binary\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        left   0.357143  1.000000  0.526316         5\n",
            "       right   1.000000  0.400000  0.571429        15\n",
            "\n",
            "    accuracy                       0.550000        20\n",
            "   macro avg   0.678571  0.700000  0.548872        20\n",
            "weighted avg   0.839286  0.550000  0.560150        20\n",
            "\n",
            "ideology_multiclass\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          left   0.000000  0.000000  0.000000         1\n",
            " moderate_left   0.400000  1.000000  0.571429         4\n",
            "moderate_right   0.500000  0.500000  0.500000        10\n",
            "         right   0.000000  0.000000  0.000000         5\n",
            "\n",
            "      accuracy                       0.450000        20\n",
            "     macro avg   0.225000  0.375000  0.267857        20\n",
            "  weighted avg   0.330000  0.450000  0.364286        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell the final F1-score is calculated as the macro-average of all the F1s obtained in the classification task (macro-f1-gender, macro-f1-profession, macro-f1-ideology_binary and macro-f1-ideology_multiclass)."
      ],
      "metadata": {
        "id": "nZO1keOevvMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = {}\n",
        "\n",
        "# Next, we are going to calculate the total result\n",
        "for label in ['gender', 'profession', 'ideology_binary', 'ideology_multiclass']:\n",
        "\n",
        "  # Get the predictions\n",
        "  y_pred = baselines[label].predict (X_test)\n",
        "\n",
        "  f1_scores[label] = f1_score(dataframes['test'][label], y_pred, average='macro')\n",
        "\n",
        "f1_scores = list (f1_scores.values ())\n",
        "\n",
        "print (\"Your final F1-score is {f1}\".format (f1 = sum(f1_scores) / len(f1_scores)))\n"
      ],
      "metadata": {
        "id": "vvOtW8blAmOh",
        "outputId": "195f69ba-053e-470e-d7c2-7d9ac1765d46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your final F1-score is 0.4237901739643226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation of the submission file\n",
        "Finally, an output file is generated with the predictions in the format required for submission to CodaLab."
      ],
      "metadata": {
        "id": "OKwxWs0l2cwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we are going to generate the output for the CodaLab submission page\n",
        "# The output order is in the same order that the testing file, thus \n",
        "# we do not need to keep any index or ID\n",
        "output_df = pd.DataFrame ()\n",
        "output_df['user'] = dataframes['test']['label']\n",
        "\n",
        "# Generate the output\n",
        "for label in ['gender', 'profession', 'ideology_binary', 'ideology_multiclass']:\n",
        "  output_df[label] = baselines[label].predict (X_test)\n",
        "\n",
        "print (output_df)\n",
        "output_df.to_csv ('results.csv', index = False)"
      ],
      "metadata": {
        "id": "akLizOcw62Eo",
        "outputId": "1dd6a68e-36a8-4884-8081-abb670d5f155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        user  gender  profession ideology_binary ideology_multiclass\n",
            "0   @user106  female  politician            left       moderate_left\n",
            "1   @user180  female  politician            left       moderate_left\n",
            "2   @user226    male  politician            left      moderate_right\n",
            "3    @user23  female  politician            left       moderate_left\n",
            "4   @user237    male  politician           right      moderate_right\n",
            "5   @user250  female  politician            left       moderate_left\n",
            "6   @user280    male  politician            left       moderate_left\n",
            "7   @user295    male  politician            left       moderate_left\n",
            "8   @user332    male  politician           right      moderate_right\n",
            "9   @user334    male  politician            left      moderate_right\n",
            "10  @user350  female  politician            left       moderate_left\n",
            "11  @user361    male  politician           right      moderate_right\n",
            "12  @user406  female  politician            left       moderate_left\n",
            "13   @user42    male  politician            left       moderate_left\n",
            "14  @user425    male  politician            left       moderate_left\n",
            "15  @user442    male  politician           right      moderate_right\n",
            "16  @user464    male  politician            left      moderate_right\n",
            "17   @user49    male  politician           right      moderate_right\n",
            "18   @user61    male  politician           right      moderate_right\n",
            "19   @user99    male  politician            left      moderate_right\n"
          ]
        }
      ]
    }
  ]
}