{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "merging users: 100%|██████████| 314/314 [00:00<00:00, 446.37it/s]\n",
      "merging users: 100%|██████████| 101/101 [00:00<00:00, 1267.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('../data/training.xls')\n",
    "test_df = pd.read_csv('../data/development.csv')\n",
    "\n",
    "def aggregate_users(df):\n",
    "    columns_to_group_by_user = ['label', 'gender', 'profession', 'ideology_binary', 'ideology_multiclass']\n",
    "\n",
    "    group = df.groupby(by = columns_to_group_by_user, dropna = False, observed = True, sort = False)\n",
    "\n",
    "    # Custom df per user\n",
    "    df_users = group[columns_to_group_by_user].agg(func = ['count'], as_index = False, observed = True).index.to_frame (index = False)\n",
    "\n",
    "    merged_fields = []\n",
    "\n",
    "    pbar = tqdm(df_users.iterrows(), total = df_users.shape[0], desc = \"merging users\")\n",
    "\n",
    "    for index, row in pbar:\n",
    "        df_user = df[(df['label'] == row['label'])]\n",
    "        merged_fields.append({**row, **{field: ' [SEP] '.join (df_user[field].fillna ('')) for field in ['tweet']}})\n",
    "\n",
    "    df = pd.DataFrame (merged_fields)\n",
    "    return df\n",
    "\n",
    "train_df = aggregate_users(train_df)\n",
    "test_df = aggregate_users(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42730\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in train_df.tweet:\n",
    "    corpus.extend([sen.split(' ') for sen in i.split('[SEP]')])\n",
    "\n",
    "for i in test_df.tweet:\n",
    "    corpus.extend([sen.split(' ') for sen in i.split('[SEP]')])\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['la'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [00:02<00:00, 153.05it/s]\n",
      "100%|██████████| 101/101 [00:00<00:00, 349.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def return_wvecs(train_df):\n",
    "    x_train = []\n",
    "    for sen in tqdm(train_df.tweet):\n",
    "        \n",
    "        sens = []\n",
    "        for ss in sen.split('[SEP]'):\n",
    "            sens.extend(ss.split(' '))\n",
    "        wvs = []\n",
    "        for w in sens:\n",
    "            wvs.append(model.wv[w])\n",
    "        wvs = np.asarray(wvs)\n",
    "        x_train.append(np.mean(wvs, axis=0))\n",
    "        \n",
    "    x_train = np.asarray(x_train)\n",
    "    return x_train\n",
    "\n",
    "xtrain = return_wvecs(train_df)\n",
    "xtest = return_wvecs(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = train_df.gender\n",
    "ytest = test_df.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23 25]\n",
      " [13 40]]\n",
      "0.6160189868865822\n",
      "{'female': {'precision': 0.6388888888888888, 'recall': 0.4791666666666667, 'f1-score': 0.5476190476190476, 'support': 48}, 'male': {'precision': 0.6153846153846154, 'recall': 0.7547169811320755, 'f1-score': 0.6779661016949153, 'support': 53}, 'accuracy': 0.6237623762376238, 'macro avg': {'precision': 0.6271367521367521, 'recall': 0.6169418238993711, 'f1-score': 0.6127925746569814, 'support': 101}, 'weighted avg': {'precision': 0.6265549631886266, 'recall': 0.6237623762376238, 'f1-score': 0.6160189868865822, 'support': 101}}\n"
     ]
    }
   ],
   "source": [
    "m = SVC(class_weight='balanced')\n",
    "\n",
    "m.fit(xtrain, ytrain)\n",
    "predictions = m.predict(xtest)\n",
    "cm =confusion_matrix(ytest, predictions)\n",
    "cr = classification_report(ytest, predictions, zero_division = 0, output_dict=True)\n",
    "print(cm)\n",
    "print(cr['weighted avg']['f1-score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| w2v | 0.6160 | 0.8516 | 0.7190 | 0.4978 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1s = []\n",
    "for label in ['gender', \t'profession' ,\t'ideology_binary', \t'ideology_multiclass']:\n",
    "    ytrain = train_df[label]\n",
    "    ytest = test_df[label]\n",
    "    m = SVC(class_weight='balanced')\n",
    "\n",
    "    m.fit(xtrain, ytrain)\n",
    "    predictions = m.predict(xtest)\n",
    "    cm =confusion_matrix(ytest, predictions)\n",
    "    \n",
    "    score = f1_score(ytest, predictions, average='micro')\n",
    "    cr = classification_report(ytest, predictions, output_dict=True)\n",
    "    f1s.append(cr['weighted avg']['f1-score'])\n",
    "\n",
    "print(f'| w2v | {f1s[0]:.4f} | {f1s[1]:.4f} | {f1s[2]:.4f} | {f1s[3]:.4f} |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|model| f1-gender | f1-profession | f1-ib | f1-im|\n",
    "|---|---|---|---|---|\n",
    "| w2v | 0.6160 | 0.8516 | 0.7190 | 0.4978 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "References:\n",
    "- https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
